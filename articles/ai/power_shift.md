## How powershift is occuring in the development of AI

We can depict Data, information, knowledge and wisdom as pyramid.  

                                  -  
          -And By giving insight that knowldege becomes wisdom-  
        --By giving that information meaning it becomes knowledge--  
      ---By giving data a context data becomes the information--------  
    ------------------data is the base of pyramid------------------------  

This is the human way on operating on data. AI doesn't work like human.. 
Data are signals for AI and they structure the data and contextualize it and then act of the actionable data.

Turing test - where AI can fool a human to think as if it's a human.
But fooling some one  and thinking someone as human is very different from actually achieving humanity.
In reality we must think about how much power we give to AI without it's knowledge and wisdom in human sense. 

Enchanted - AI is presented as magical beyond human knowledge ( there was a day when people were seeing wifi as magical and tried different experiements to boost signals without understanding how it works )
Determinism - AI detects patterns that exists in the world - it is very deterministic.

If we take the example of AlphaGo it just try to match the pattern from the previous competetions when the user takes a step and determines the best possible next safe step. Purely based on patterns and without the knowledge like a human.  So it's very easy to do adversarial attacks with machine learning models by intentionally manipulating input data or patterns. Another example could be - it may be possible to trick an AI system to see a STOP sign as an Yield Sign with an adversarial attack. An attacker could wreak havoc on roads populated by self driving cars by manipulating the input and misrecognizing stop signs. Imagine how much of disadvantage or problems this can bring to traffic safety with autonomous vehicles. So in a way we are giving power to a system without Knowledge and it can bring a huge problem in society.

It is the starting point for humans but not the ending point for humans ! One example is AlphaGo the AI wich beats the go game ..
this catully was playing by recognising the patterns from the earlier games on taking a step. 
So AI can easily be exploited easily by adversarial machine learning .

Deep learning may deepen existing power imbalances between those who creates the technology and those on whom they act. 
It is the from of power without knowledge.

Mainstream research is creating systems that are extraordinarily expensive to train, further empowering already powerful institutions, 
from Amazon, Google and Facebook to domestic surveillance and military programmes.

Many researchers have trouble seeing their intellectual work with AI as furthering inequity. Researchers such as me spend our days working on what are, to us, mathematically
beautiful and useful systems, and hearing of AI success stories, such as winning Go championships or showing promise in detecting cancer. 
Researchers in AI overwhelmingly focus on providing highly accurate information to decision makers. Remarkably little research focuses on serving data subjects.

Organizations have responded with pledges to design ‘fair’ and ‘transparent’ systems, but fair and transparent according to whom?
These systems sometimes mitigate harm, but are controlled by powerful institutions with their own agendas. At best, they are unreliable; at worst, they masquerade as
‘ethics-washing’ technologies that still perpetuate inequity. It is our responsibility to recognize our skewed perspective and listen to those impacted by AI.

We should strive to create a society where we want to live—a society where we are not merely subjects of AI, but where our values, privacy, and opinions are respected and actively integrated into building the system. We should participate or allowed to be participated in building the system, not just using it and pay for it and chant about it.



